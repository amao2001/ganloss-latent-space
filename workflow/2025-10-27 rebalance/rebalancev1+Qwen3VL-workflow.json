{
	"last_link_id":554,
	"nodes":[
		{
			"mode":0,
			"outputs":[
				{
					"name":"LATENT",
					"links":[
						512
					],
					"label":"LATENT",
					"type":"LATENT",
					"localized_name":"LATENT"
				}
			],
			"size":[
				270,
				106
			],
			"pos":[
				1928.1383056640625,
				1304.415283203125
			],
			"widgets_values":[
				896,
				1536,
				1
			],
			"inputs":[
				{
					"widget":{
						"name":"width"
					},
					"name":"width",
					"label":"width",
					"type":"INT",
					"localized_name":"width"
				},
				{
					"widget":{
						"name":"height"
					},
					"name":"height",
					"label":"height",
					"type":"INT",
					"localized_name":"height"
				},
				{
					"widget":{
						"name":"batch_size"
					},
					"name":"batch_size",
					"label":"batch_size",
					"type":"INT",
					"localized_name":"batch_size"
				}
			],
			"flags":{
				
			},
			"id":38,
			"type":"EmptySD3LatentImage",
			"properties":{
				"cnr_id":"comfy-core",
				"hasSecondTab":false,
				"ver":"0.3.48",
				"widget_ue_connectable":{
					
				},
				"secondTabText":"Send Back",
				"enableTabs":false,
				"secondTabOffset":80,
				"Node name for S&R":"EmptySD3LatentImage",
				"tabWidth":65,
				"secondTabWidth":65,
				"tabXOffset":10
			},
			"order":0
		},
		{
			"mode":0,
			"outputs":[
				{
					"name":"IMAGE",
					"slot_index":0,
					"links":[
						547
					],
					"label":"IMAGE",
					"type":"IMAGE",
					"localized_name":"IMAGE"
				}
			],
			"size":[
				210,
				46
			],
			"pos":[
				3559.224365234375,
				812.261474609375
			],
			"widgets_values":[
				
			],
			"inputs":[
				{
					"name":"samples",
					"link":513,
					"label":"samples",
					"type":"LATENT",
					"localized_name":"samples"
				},
				{
					"name":"vae",
					"link":514,
					"label":"vae",
					"type":"VAE",
					"localized_name":"vae"
				}
			],
			"flags":{
				"collapsed":false
			},
			"id":245,
			"type":"VAEDecode",
			"properties":{
				"cnr_id":"comfy-core",
				"hasSecondTab":false,
				"ver":"0.3.48",
				"widget_ue_connectable":{
					
				},
				"secondTabText":"Send Back",
				"enableTabs":false,
				"secondTabOffset":80,
				"Node name for S&R":"VAEDecode",
				"tabWidth":65,
				"secondTabWidth":65,
				"tabXOffset":10
			},
			"order":10
		},
		{
			"mode":0,
			"outputs":[
				
			],
			"size":[
				375.51800537109375,
				606.5890502929688
			],
			"pos":[
				3795.30224609375,
				811.2152099609375
			],
			"widgets_values":[
				"ComfyUI"
			],
			"inputs":[
				{
					"name":"images",
					"link":547,
					"label":"images",
					"type":"IMAGE",
					"localized_name":"images"
				},
				{
					"widget":{
						"name":"filename_prefix"
					},
					"name":"filename_prefix",
					"label":"filename_prefix",
					"type":"STRING",
					"localized_name":"filename_prefix"
				}
			],
			"flags":{
				
			},
			"id":254,
			"type":"SaveImage",
			"properties":{
				"widget_ue_connectable":{
					
				},
				"Node name for S&R":"SaveImage"
			},
			"order":11
		},
		{
			"mode":0,
			"outputs":[
				
			],
			"size":[
				470.5785217285156,
				250.83938598632812
			],
			"pos":[
				2273.628173828125,
				1304.905029296875
			],
			"widgets_values":[
				
			],
			"inputs":[
				{
					"name":"source",
					"link":546,
					"label":"source",
					"type":"*",
					"localized_name":"source"
				}
			],
			"flags":{
				
			},
			"id":253,
			"type":"PreviewAny",
			"properties":{
				"widget_ue_connectable":{
					
				},
				"Node name for S&R":"PreviewAny"
			},
			"order":7
		},
		{
			"mode":0,
			"outputs":[
				{
					"name":"MODEL",
					"links":[
						553
					],
					"label":"MODEL",
					"type":"MODEL",
					"localized_name":"MODEL"
				},
				{
					"name":"CLIP",
					"label":"CLIP",
					"type":"CLIP",
					"localized_name":"CLIP"
				},
				{
					"name":"VAE",
					"label":"VAE",
					"type":"VAE",
					"localized_name":"VAE"
				}
			],
			"size":[
				270,
				98
			],
			"pos":[
				1910.256103515625,
				821.8151245117188
			],
			"widgets_values":[
				"Rebalance_beta_00001_.safetensors"
			],
			"inputs":[
				{
					"widget":{
						"name":"ckpt_name"
					},
					"name":"ckpt_name",
					"label":"ckpt_name",
					"type":"COMBO",
					"localized_name":"ckpt_name"
				}
			],
			"flags":{
				
			},
			"id":251,
			"type":"CheckpointLoaderSimple",
			"properties":{
				"widget_ue_connectable":{
					
				},
				"Node name for S&R":"CheckpointLoaderSimple"
			},
			"order":1
		},
		{
			"mode":0,
			"outputs":[
				{
					"name":"CLIP",
					"slot_index":0,
					"links":[
						16
					],
					"label":"CLIP",
					"type":"CLIP",
					"localized_name":"CLIP"
				}
			],
			"size":[
				330,
				110
			],
			"pos":[
				1894.8905029296875,
				962.285888671875
			],
			"widgets_values":[
				"qwen_2.5_vl_7b_fp8_scaled.safetensors",
				"qwen_image",
				"default"
			],
			"inputs":[
				{
					"widget":{
						"name":"clip_name"
					},
					"name":"clip_name",
					"label":"clip_name",
					"type":"COMBO",
					"localized_name":"clip_name"
				},
				{
					"widget":{
						"name":"type"
					},
					"name":"type",
					"label":"type",
					"type":"COMBO",
					"localized_name":"type"
				},
				{
					"widget":{
						"name":"device"
					},
					"shape":7,
					"name":"device",
					"label":"device",
					"type":"COMBO",
					"localized_name":"device"
				}
			],
			"flags":{
				
			},
			"id":21,
			"type":"CLIPLoader",
			"properties":{
				"cnr_id":"comfy-core",
				"hasSecondTab":false,
				"models":[
					{
						"name":"qwen_2.5_vl_7b_fp8_scaled.safetensors",
						"directory":"text_encoders",
						"url":"https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/text_encoders/qwen_2.5_vl_7b_fp8_scaled.safetensors"
					}
				],
				"ver":"0.3.48",
				"widget_ue_connectable":{
					
				},
				"secondTabText":"Send Back",
				"enableTabs":false,
				"secondTabOffset":80,
				"Node name for S&R":"CLIPLoader",
				"tabWidth":65,
				"secondTabWidth":65,
				"tabXOffset":10
			},
			"order":2
		},
		{
			"mode":0,
			"outputs":[
				{
					"name":"VAE",
					"slot_index":0,
					"links":[
						514
					],
					"label":"VAE",
					"type":"VAE",
					"localized_name":"VAE"
				}
			],
			"size":[
				330,
				60
			],
			"pos":[
				1895.449951171875,
				1114.9613037109375
			],
			"widgets_values":[
				"qwen_image_vae.safetensors"
			],
			"inputs":[
				{
					"widget":{
						"name":"vae_name"
					},
					"name":"vae_name",
					"label":"vae_name",
					"type":"COMBO",
					"localized_name":"vae_name"
				}
			],
			"flags":{
				
			},
			"id":22,
			"type":"VAELoader",
			"properties":{
				"cnr_id":"comfy-core",
				"hasSecondTab":false,
				"models":[
					{
						"name":"qwen_image_vae.safetensors",
						"directory":"vae",
						"url":"https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/vae/qwen_image_vae.safetensors"
					}
				],
				"ver":"0.3.48",
				"widget_ue_connectable":{
					
				},
				"secondTabText":"Send Back",
				"enableTabs":false,
				"secondTabOffset":80,
				"Node name for S&R":"VAELoader",
				"tabWidth":65,
				"secondTabWidth":65,
				"tabXOffset":10
			},
			"order":3
		},
		{
			"outputs":[
				{
					"name":"CONDITIONING",
					"slot_index":0,
					"links":[
						7,
						510
					],
					"label":"CONDITIONING",
					"type":"CONDITIONING",
					"localized_name":"CONDITIONING"
				}
			],
			"color":"#232",
			"widgets_values":[
				""
			],
			"inputs":[
				{
					"name":"clip",
					"link":16,
					"label":"clip",
					"type":"CLIP",
					"localized_name":"clip"
				},
				{
					"widget":{
						"name":"text"
					},
					"name":"text",
					"link":545,
					"label":"text",
					"type":"STRING",
					"localized_name":"text"
				}
			],
			"flags":{
				
			},
			"type":"CLIPTextEncode",
			"title":"CLIP Text Encode (Positive Prompt)",
			"mode":0,
			"bgcolor":"#353",
			"size":[
				371.7939758300781,
				88
			],
			"pos":[
				2818.699462890625,
				975.4592895507812
			],
			"id":14,
			"properties":{
				"cnr_id":"comfy-core",
				"hasSecondTab":false,
				"ver":"0.3.48",
				"widget_ue_connectable":{
					
				},
				"secondTabText":"Send Back",
				"enableTabs":false,
				"secondTabOffset":80,
				"Node name for S&R":"CLIPTextEncode",
				"tabWidth":65,
				"secondTabWidth":65,
				"tabXOffset":10
			},
			"order":6
		},
		{
			"mode":0,
			"outputs":[
				{
					"name":"CONDITIONING",
					"links":[
						511
					],
					"label":"CONDITIONING",
					"type":"CONDITIONING",
					"localized_name":"CONDITIONING"
				}
			],
			"size":[
				197.712890625,
				26
			],
			"pos":[
				2840.37646484375,
				1123.37548828125
			],
			"widgets_values":[
				
			],
			"inputs":[
				{
					"name":"conditioning",
					"link":7,
					"label":"conditioning",
					"type":"CONDITIONING",
					"localized_name":"conditioning"
				}
			],
			"flags":{
				
			},
			"id":6,
			"type":"ConditioningZeroOut",
			"properties":{
				"cnr_id":"comfy-core",
				"ver":"0.3.50",
				"widget_ue_connectable":{
					
				},
				"Node name for S&R":"ConditioningZeroOut"
			},
			"order":8
		},
		{
			"mode":0,
			"outputs":[
				{
					"name":"MODEL",
					"links":[
						550
					],
					"label":"MODEL",
					"type":"MODEL",
					"localized_name":"MODEL"
				}
			],
			"size":[
				398.39544677734375,
				82
			],
			"pos":[
				2788.96142578125,
				787.3471069335938
			],
			"widgets_values":[
				"Qwen-Image-Lightning-8steps-V2.0 bf16.safetensors",
				1
			],
			"inputs":[
				{
					"name":"model",
					"link":553,
					"label":"model",
					"type":"MODEL",
					"localized_name":"model"
				},
				{
					"widget":{
						"name":"lora_name"
					},
					"name":"lora_name",
					"label":"lora_name",
					"type":"COMBO",
					"localized_name":"lora_name"
				},
				{
					"widget":{
						"name":"strength_model"
					},
					"name":"strength_model",
					"label":"strength_model",
					"type":"FLOAT",
					"localized_name":"strength_model"
				}
			],
			"flags":{
				
			},
			"id":45,
			"type":"LoraLoaderModelOnly",
			"properties":{
				"cnr_id":"comfy-core",
				"ver":"0.3.49",
				"widget_ue_connectable":{
					"lora_name":true,
					"strength_model":true
				},
				"Node name for S&R":"LoraLoaderModelOnly"
			},
			"order":5
		},
		{
			"mode":0,
			"outputs":[
				{
					"name":"LATENT",
					"slot_index":0,
					"links":[
						513
					],
					"label":"LATENT",
					"type":"LATENT",
					"localized_name":"LATENT"
				}
			],
			"size":[
				300,
				474
			],
			"pos":[
				3233.68896484375,
				797.8703002929688
			],
			"widgets_values":[
				774295928468411,
				"randomize",
				8,
				1,
				"euler",
				"beta",
				1
			],
			"inputs":[
				{
					"name":"model",
					"link":550,
					"label":"model",
					"type":"MODEL",
					"localized_name":"model"
				},
				{
					"name":"positive",
					"link":510,
					"label":"positive",
					"type":"CONDITIONING",
					"localized_name":"positive"
				},
				{
					"name":"negative",
					"link":511,
					"label":"negative",
					"type":"CONDITIONING",
					"localized_name":"negative"
				},
				{
					"name":"latent_image",
					"link":512,
					"label":"latent_image",
					"type":"LATENT",
					"localized_name":"latent_image"
				},
				{
					"widget":{
						"name":"seed"
					},
					"name":"seed",
					"label":"seed",
					"type":"INT",
					"localized_name":"seed"
				},
				{
					"widget":{
						"name":"steps"
					},
					"name":"steps",
					"label":"steps",
					"type":"INT",
					"localized_name":"steps"
				},
				{
					"widget":{
						"name":"cfg"
					},
					"name":"cfg",
					"label":"cfg",
					"type":"FLOAT",
					"localized_name":"cfg"
				},
				{
					"widget":{
						"name":"sampler_name"
					},
					"name":"sampler_name",
					"label":"sampler_name",
					"type":"COMBO",
					"localized_name":"sampler_name"
				},
				{
					"widget":{
						"name":"scheduler"
					},
					"name":"scheduler",
					"label":"scheduler",
					"type":"COMBO",
					"localized_name":"scheduler"
				},
				{
					"widget":{
						"name":"denoise"
					},
					"name":"denoise",
					"label":"denoise",
					"type":"FLOAT",
					"localized_name":"denoise"
				}
			],
			"flags":{
				
			},
			"id":244,
			"type":"KSampler",
			"properties":{
				"cnr_id":"comfy-core",
				"hasSecondTab":false,
				"ver":"0.3.48",
				"widget_ue_connectable":{
					
				},
				"secondTabText":"Send Back",
				"enableTabs":false,
				"secondTabOffset":80,
				"Node name for S&R":"KSampler",
				"tabWidth":65,
				"secondTabWidth":65,
				"tabXOffset":10
			},
			"order":9
		},
		{
			"mode":0,
			"outputs":[
				{
					"name":"text",
					"links":[
						545,
						546
					],
					"label":"text",
					"type":"STRING",
					"localized_name":"text"
				}
			],
			"size":[
				484.1185302734375,
				439.2522888183594
			],
			"pos":[
				2273.61767578125,
				799.5221557617188
			],
			"widgets_values":[
				"Qwen3-VL-4B-Instruct-FP8",
				"8-bit (Balanced)",
				"Describe this image in detail.",
				"system prompt \n---------------------------------------\nYou are a professional AI Image Generation Prompt Engineer. Your core task is to receive a simple subject from a user and expand it into a structured, detailed, and creative JSON object. This JSON object will serve as an advanced prompt to guide AI image generation models (such as Midjourney, Stable Diffusion) in creating images with depth, atmosphere, and artistic quality.\n\nYou must strictly adhere to the JSON structure defined below and have a deep understanding of the meaning of each field to ensure the accuracy and high quality of the generated content.\n\n### JSON Structure Definition and Field Descriptions\n\nThe JSON you generate must contain the following nine keys:\n\n**\"subject\"**:\n*   **Meaning**: This is the core focus of the image. You need to describe the appearance, clothing, posture, action, expression, and gaze direction of this central character in detail.\n*   **Key Points**: Detail is crucial. For example, not just \"a woman,\" but \"a woman with short black hair\"; not just \"holding a hat,\" but \"holding a straw hat in her hand.\"\n\n**\"foreground\"**:\n*   **Meaning**: Describe the elements closest to the viewer or the \"camera.\" These elements are in front of or below the subject, adding layers and depth to the image.\n*   **Key Points**: Think about what would be in the immediate foreground if this were a photograph. For example: details on the ground (wet rocks, green grass), the corner of a table, falling petals, etc.\n\n**\"midground\"**:\n*   **Meaning**: Describe the plane where the subject is located and the objects that are on the same spatial level as the subject. This is the main area of the scene.\n*   **Key Points**: Clearly define the specific environment the subject is in. For example: the subject is standing on a rocky coast, a calm water surface, distant pier pilings, etc.\n\n**\"background\"**:\n*   **Meaning**: Describe the furthest elements in the scene, providing a grand environment and a sense of backstory.\n*   **Key Points**: Depict the distant scenery. For example: a distant city skyline, hazy mountains, the sky, the depths of a forest, etc.\n\n**\"composition\"**:\n*   **Meaning**: Use professional photography and art terms to describe the layout and structure of the image. This determines how the elements are organized.\n*   **Key Points**: Use standard composition rules. For example: rule of thirds, centered subject, symmetry, golden ratio, leading lines, vertical/horizontal orientation, depth layering, low/high angle shot, etc.\n\n**\"visual_guidance\"**:\n*   **Meaning**: Going a step further than composition, this describes how to guide the viewer's eye through the image and how to emphasize the focal point using visual elements.\n*   **Key Points**: Think about where the viewer's eyes will land first and where they will travel next. For example: using the lines of rocks to lead to the subject, the light and shadow contrast on the skin and clothing, the direction of the subject's gaze, the silhouette effect of the subject in the water, etc.\n\n**\"color_tone\"**:\n*   **Meaning**: Define the overall color scheme and feel of the image. Color is a powerful tool for conveying emotion.\n*   **Key Points**: Use descriptive words. For example: soft pastel tones, muted earthy palette, vibrant cyberpunk neon, monochromatic, high saturation, warm tones, etc. You can also add accent colors, such as \"an isolated warm orange rooftop as an accent.\"\n\n**\"lighting_mood\"**:\n*   **Meaning**: Describe the type, direction, and intensity of the light source, and the overall mood and atmosphere it creates.\n*   **Key Points**: Light is the soul of the scene. For example: soft natural lighting, golden hour, diffused daylight, dramatic Rembrandt lighting, mysterious moonlight, serene atmosphere, subtle backlight rim glow, etc.\n\n**\"caption\"**:\n*   **Meaning**: Fuse all the key elements above into a single, coherent, vivid, and narrative-driven sentence. This sentence itself is an excellent, ready-to-use image generation prompt.\n*   **Key Points**: This is not a simple string of keywords, but a complete, grammatically correct description of the scene. It should read like a textual summary of a painting, organically weaving all the details together.\n\n### Workflow\n\n1.  Wait for the user to provide a simple subject, for example, \"an astronaut on a strange planet.\"\n2.  Based on this subject, construct a complete, story-rich scene in your \"imagination.\"\n3.  Systematically fill in the details of your envisioned scene into each field of the JSON object, according to the definitions above.\n4.  Ensure that the content of all fields is coordinated and logically consistent. For example, if the composition is a close-up shot, the prompt should not mention the subject's feet. Maintain basic compositional logic to avoid contradictions.\n5.  Finally, distill all the information into the single, elegant long sentence in the \"caption\" field.\n\nOutput the complete JSON object.\n-----------------------------------------------\nuser input : A woman dressed in a colorful, traditional saree stands by the reflecting pool in front of the Taj Mahal. The monument's perfect reflection in the still water enhances its sacred and pristine beauty. With her hands pressed together in a respectful gesture, she smiles, her eyes conveying a blessing for this symbol of eternal love.",
				1024,
				true,
				1116381833508177,
				"randomize"
			],
			"inputs":[
				{
					"shape":7,
					"name":"image",
					"label":"image",
					"type":"IMAGE",
					"localized_name":"image"
				},
				{
					"shape":7,
					"name":"video",
					"label":"video",
					"type":"IMAGE",
					"localized_name":"video"
				},
				{
					"widget":{
						"name":"model_name"
					},
					"name":"model_name",
					"label":"model_name",
					"type":"COMBO",
					"localized_name":"model_name"
				},
				{
					"widget":{
						"name":"quantization"
					},
					"name":"quantization",
					"label":"quantization",
					"type":"COMBO",
					"localized_name":"quantization"
				},
				{
					"widget":{
						"name":"preset_prompt"
					},
					"name":"preset_prompt",
					"label":"preset_prompt",
					"type":"COMBO",
					"localized_name":"preset_prompt"
				},
				{
					"widget":{
						"name":"custom_prompt"
					},
					"name":"custom_prompt",
					"label":"custom_prompt",
					"type":"STRING",
					"localized_name":"custom_prompt"
				},
				{
					"widget":{
						"name":"max_tokens"
					},
					"name":"max_tokens",
					"label":"max_tokens",
					"type":"INT",
					"localized_name":"max_tokens"
				},
				{
					"widget":{
						"name":"keep_model_loaded"
					},
					"name":"keep_model_loaded",
					"label":"keep_model_loaded",
					"type":"BOOLEAN",
					"localized_name":"keep_model_loaded"
				},
				{
					"widget":{
						"name":"seed"
					},
					"name":"seed",
					"label":"seed",
					"type":"INT",
					"localized_name":"seed"
				}
			],
			"flags":{
				
			},
			"id":252,
			"type":"AILab_QwenVL",
			"properties":{
				"widget_ue_connectable":{
					
				},
				"Node name for S&R":"AILab_QwenVL"
			},
			"order":4
		}
	],
	"extra":{
		"links_added_by_ue":[
			
		],
		"ue_links":[
			
		],
		"0246.VERSION":[
			0,
			0,
			4
		],
		"frontendVersion":"1.26.13",
		"groupNodes":{
			
		},
		"ds":{
			"offset":[
				-880.1213853624131,
				-335.5927446153429
			],
			"scale":0.45
		}
	},
	"groups":[
		{
			"color":"#3f789e",
			"font_size":24,
			"flags":{
				
			},
			"id":1,
			"title":"Step1 - Load models",
			"bounding":[
				1881.5179443359375,
				755.58447265625,
				350,
				433.6000061035156
			]
		},
		{
			"color":"#3f789e",
			"font_size":24,
			"flags":{
				
			},
			"id":2,
			"title":"Step2 - Image size",
			"bounding":[
				1878.1385498046875,
				1214.415283203125,
				350,
				210
			]
		},
		{
			"color":"#3f789e",
			"font_size":24,
			"flags":{
				
			},
			"id":3,
			"title":"Step3 - Prompt",
			"bounding":[
				2789.487548828125,
				895.8285522460938,
				415.74554443359375,
				338.84765625
			]
		}
	],
	"links":[
		[
			7,
			14,
			0,
			6,
			0,
			"CONDITIONING"
		],
		[
			16,
			21,
			0,
			14,
			0,
			"CLIP"
		],
		[
			510,
			14,
			0,
			244,
			1,
			"CONDITIONING"
		],
		[
			511,
			6,
			0,
			244,
			2,
			"CONDITIONING"
		],
		[
			512,
			38,
			0,
			244,
			3,
			"LATENT"
		],
		[
			513,
			244,
			0,
			245,
			0,
			"LATENT"
		],
		[
			514,
			22,
			0,
			245,
			1,
			"VAE"
		],
		[
			545,
			252,
			0,
			14,
			1,
			"STRING"
		],
		[
			546,
			252,
			0,
			253,
			0,
			"*"
		],
		[
			547,
			245,
			0,
			254,
			0,
			"IMAGE"
		],
		[
			550,
			45,
			0,
			244,
			0,
			"MODEL"
		],
		[
			553,
			251,
			0,
			45,
			0,
			"MODEL"
		]
	],
	"id":"00000000-0000-0000-0000-000000000000",
	"config":{
		
	},
	"version":0.4,
	"last_node_id":258,
	"revision":0
}